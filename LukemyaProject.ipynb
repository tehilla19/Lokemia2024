{"cells":[{"cell_type":"code","source":["%cd /content/drive//MyDrive/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"774-vz_nJcTH","executionInfo":{"status":"ok","timestamp":1716833615940,"user_tz":-180,"elapsed":306,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"97ef740d-e219-4e87-c0d1-d09cb84e4328"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["!mkdir GitEx"],"metadata":{"id":"UkHmUB0pPFqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0sLDM41MFhS","executionInfo":{"status":"ok","timestamp":1716833665950,"user_tz":-180,"elapsed":777,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"11efebc1-e027-4efb-ed70-66e7bac873e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/drive/MyDrive/GitEx/.git/\n"]}]},{"cell_type":"code","source":["!git config --global init.defaultBranch main"],"metadata":{"id":"05JddbuxXs9T","executionInfo":{"status":"ok","timestamp":1716835518964,"user_tz":-180,"elapsed":318,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["!git remote add tehilla19 https://github.com/tehilla19/Lokemia2024.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePys8DiUMRQq","executionInfo":{"status":"ok","timestamp":1716835524699,"user_tz":-180,"elapsed":344,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"d03c5bde-bc5c-4b46-e6ce-5e480059f38a"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["error: remote tehilla19 already exists.\n"]}]},{"cell_type":"code","source":["!git add .\n"],"metadata":{"id":"1MspHC20RwT9","executionInfo":{"status":"ok","timestamp":1716835623789,"user_tz":-180,"elapsed":318,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"t0s4ixHtYLKj"}},{"cell_type":"code","source":["!git commit -a -m \"stage 1\"\n","!git remote add tehilla19 https://github.com/tehilla19/Lokemia2024.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kvb9R3uYjKJ","executionInfo":{"status":"ok","timestamp":1716835841514,"user_tz":-180,"elapsed":771,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"4bd6d937-673e-4523-91ee-b1cdb4bdb940"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch master\n","\n","Initial commit\n","\n","nothing to commit (create/copy files and use \"git add\" to track)\n","error: remote tehilla19 already exists.\n"]}]},{"cell_type":"code","source":["!git br"],"metadata":{"id":"YgX8gBdnX61g","executionInfo":{"status":"ok","timestamp":1716835597017,"user_tz":-180,"elapsed":336,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_q0vQYc41ki3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHNPN6Uk2SsI"},"outputs":[],"source":["y = pd.read_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/actual_ALL_AML.csv', delimiter='\\t')\n","\n","train = pd.read_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/דאטא 1 מתוקן.xlsx - data_set_ALL_AML_train.csv')\n","\n","test = pd.read_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/דאטא 2 מתוקן - data_set_ALL_AML_independent.csv')"]},{"cell_type":"markdown","metadata":{"id":"beNeNVEdUKbe"},"source":["מפרידה את העמודות לשני עמודות עם כותרות שיקל בזיהוי"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1716795792143,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"-EiOjP1z_YOF","outputId":"3d195cd0-7b67-4456-a9f8-2d0bf03e10d6","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# Split 'patient,cancer' column into two separate columns\\ny_data[['patient', 'cancer']] = y_data['patient,cancer'].str.split(',', expand=True)\\n\\n# Drop the original 'patient,cancer' column\\ny = y_data.drop('patient,cancer', axis=1)\\n\\n# Display the modified 'cancer_mapping' dataframe\\nprint(y.head())\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}],"source":["'''\n","# Split 'patient,cancer' column into two separate columns\n","y_data[['patient', 'cancer']] = y_data['patient,cancer'].str.split(',', expand=True)\n","\n","# Drop the original 'patient,cancer' column\n","y = y_data.drop('patient,cancer', axis=1)\n","\n","# Display the modified 'cancer_mapping' dataframe\n","print(y.head())\n","'''\n"]},{"cell_type":"markdown","metadata":{"id":"9S0ais52Uytb"},"source":["מדפיסה לראות את הכותרות של העמודות בכל קובץ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1716795792143,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"Z2g13AY-DG7I","outputId":"0aac8365-1439-4458-8560-2375b5d47152","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["y columns: Index(['patient,cancer'], dtype='object')\n","train columns: Index(['Gene Description', 'Gene Accession Number', '1', '2', '3', '4', '5',\n","       '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17',\n","       '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '34', '35',\n","       '36', '37', '38', '28', '29', '30', '31', '32', '33'],\n","      dtype='object')\n","test columns: Index(['Gene Description', 'Gene Accession Number', '39', '40', '42', '47',\n","       '48', '49', '41', '43', '44', '45', '46', '70', '71', '72', '68', '69',\n","       '67', '55', '56', '59', '52', '53', '51', '50', '54', '57', '58', '60',\n","       '61', '65', '66', '63', '64', '62'],\n","      dtype='object')\n"]}],"source":["print(\"y columns:\", y.columns)\n","print(\"train columns:\", train.columns)\n","print(\"test columns:\", test.columns)"]},{"cell_type":"markdown","source":["מדפיסה את ההתחלה של כל קובץ כדי להבין יותר את הדאטא"],"metadata":{"id":"BazUWB1M3yS1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLcOSUrpA9fZ","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1716795792143,"user_tz":-180,"elapsed":39,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"db064b7f-c6bf-4eef-e224-4d52985312d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["                      Gene Description Gene Accession Number    1    2    3  \\\n","0  AFFX-BioB-5_at (endogenous control)        AFFX-BioB-5_at -214 -139  -76   \n","1  AFFX-BioB-M_at (endogenous control)        AFFX-BioB-M_at -153  -73  -49   \n","2  AFFX-BioB-3_at (endogenous control)        AFFX-BioB-3_at  -58   -1 -307   \n","3  AFFX-BioC-5_at (endogenous control)        AFFX-BioC-5_at   88  283  309   \n","4  AFFX-BioC-3_at (endogenous control)        AFFX-BioC-3_at -295 -264 -376   \n","\n","     4    5    6    7    8  ...   35   36   37   38   28   29   30   31   32  \\\n","0 -135 -106 -138  -72 -413  ...    7 -213  -25  -72   -4   15 -318  -32 -124   \n","1 -114 -125  -85 -144 -260  ... -100 -252  -20 -139 -116 -114 -192  -49  -79   \n","2  265  -76  215  238    7  ...  -57  136  124   -1 -125    2  -95   49  -37   \n","3   12  168   71   55   -2  ...  132  318  325  392  241  193  312  230  330   \n","4 -419 -230 -272 -399 -541  ... -377 -209 -396 -324 -191  -51 -139 -367 -188   \n","\n","    33  \n","0 -135  \n","1 -186  \n","2  -70  \n","3  337  \n","4 -407  \n","\n","[5 rows x 40 columns]\n","                      Gene Description Gene Accession Number   39   40   42  \\\n","0  AFFX-BioB-5_at (endogenous control)        AFFX-BioB-5_at -342  -87   22   \n","1  AFFX-BioB-M_at (endogenous control)        AFFX-BioB-M_at -200 -248 -153   \n","2  AFFX-BioB-3_at (endogenous control)        AFFX-BioB-3_at   41  262   17   \n","3  AFFX-BioC-5_at (endogenous control)        AFFX-BioC-5_at  328  295  276   \n","4  AFFX-BioC-3_at (endogenous control)        AFFX-BioC-3_at -224 -226 -211   \n","\n","    47   48   49   41   43  ...   54   57   58   60   61   65   66   63   64  \\\n","0 -243 -130 -256  -62   86  ...  -90 -137 -157 -172  -47  -62  -58 -161  -48   \n","1 -218 -177 -249  -23  -36  ...  -87  -51 -370 -122 -442 -198 -217 -215 -531   \n","2 -163  -28 -410   -7 -141  ...  102  -82  -77   38  -21   -5   63  -46 -124   \n","3  182  266   24  142  252  ...  319  178  340   31  396  141   95  146  431   \n","4 -289 -170 -535 -233 -201  ... -283 -135 -438 -201 -351 -256 -191 -172 -496   \n","\n","    62  \n","0 -176  \n","1 -284  \n","2  -81  \n","3    9  \n","4 -294  \n","\n","[5 rows x 36 columns]\n"]}],"source":["print(train.head())\n","print(test.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1716795792144,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"BxqXXbne-15C","outputId":"4eb90dcf-f07d-48c0-8152-626e1b5cb4bb","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["train Information:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7129 entries, 0 to 7128\n","Data columns (total 40 columns):\n"," #   Column                 Non-Null Count  Dtype \n","---  ------                 --------------  ----- \n"," 0   Gene Description       7129 non-null   object\n"," 1   Gene Accession Number  7129 non-null   object\n"," 2   1                      7129 non-null   int64 \n"," 3   2                      7129 non-null   int64 \n"," 4   3                      7129 non-null   int64 \n"," 5   4                      7129 non-null   int64 \n"," 6   5                      7129 non-null   int64 \n"," 7   6                      7129 non-null   int64 \n"," 8   7                      7129 non-null   int64 \n"," 9   8                      7129 non-null   int64 \n"," 10  9                      7129 non-null   int64 \n"," 11  10                     7129 non-null   int64 \n"," 12  11                     7129 non-null   int64 \n"," 13  12                     7129 non-null   int64 \n"," 14  13                     7129 non-null   int64 \n"," 15  14                     7129 non-null   int64 \n"," 16  15                     7129 non-null   int64 \n"," 17  16                     7129 non-null   int64 \n"," 18  17                     7129 non-null   int64 \n"," 19  18                     7129 non-null   int64 \n"," 20  19                     7129 non-null   int64 \n"," 21  20                     7129 non-null   int64 \n"," 22  21                     7129 non-null   int64 \n"," 23  22                     7129 non-null   int64 \n"," 24  23                     7129 non-null   int64 \n"," 25  24                     7129 non-null   int64 \n"," 26  25                     7129 non-null   int64 \n"," 27  26                     7129 non-null   int64 \n"," 28  27                     7129 non-null   int64 \n"," 29  34                     7129 non-null   int64 \n"," 30  35                     7129 non-null   int64 \n"," 31  36                     7129 non-null   int64 \n"," 32  37                     7129 non-null   int64 \n"," 33  38                     7129 non-null   int64 \n"," 34  28                     7129 non-null   int64 \n"," 35  29                     7129 non-null   int64 \n"," 36  30                     7129 non-null   int64 \n"," 37  31                     7129 non-null   int64 \n"," 38  32                     7129 non-null   int64 \n"," 39  33                     7129 non-null   int64 \n","dtypes: int64(38), object(2)\n","memory usage: 2.2+ MB\n","None\n","\n","test Statistics:\n","                 39            40            42            47            48  \\\n","count   7129.000000   7129.000000   7129.000000   7129.000000   7129.000000   \n","mean     582.194978    527.819329    603.813719    576.027213    751.464862   \n","std     2473.986881   2304.800191   2377.775459   2436.848381   2437.815002   \n","min   -21984.000000 -21296.000000 -10481.000000  -7861.000000 -16945.000000   \n","25%      -33.000000    -36.000000    -17.000000     -8.000000     -6.000000   \n","50%      125.000000    124.000000    116.000000    126.000000    158.000000   \n","75%      439.000000    424.000000    420.000000    374.000000    577.000000   \n","max    45815.000000  29136.000000  37529.000000  43221.000000  25231.000000   \n","\n","                 49            41            43            44            45  \\\n","count   7129.000000   7129.000000   7129.000000   7129.000000   7129.000000   \n","mean     601.516763    565.152476    563.614252    531.401599    530.194137   \n","std     2432.454360   2352.036107   2521.409254   2335.848476   2368.906095   \n","min   -26775.000000  -7764.000000 -13905.000000  -9619.000000  -5353.000000   \n","25%      -65.000000     -7.000000    -21.000000    -45.000000    -59.000000   \n","50%      139.000000     93.000000    110.000000     74.000000     78.000000   \n","75%      552.000000    342.000000    372.000000    321.000000    327.000000   \n","max    29500.000000  31076.000000  49432.000000  35402.000000  34741.000000   \n","\n","       ...           54            57            58            60  \\\n","count  ...   7129.00000   7129.000000   7129.000000   7129.000000   \n","mean   ...    668.70122    497.195820    561.964371    561.004629   \n","std    ...   2505.06701   2436.468032   2688.424072   2615.321812   \n","min    ... -11978.00000 -11067.000000 -16131.000000  -9338.000000   \n","25%    ...    -10.00000    -27.000000    -49.000000    -19.000000   \n","50%    ...    151.00000     82.000000    129.000000     98.000000   \n","75%    ...    469.00000    296.000000    435.000000    321.000000   \n","max    ...  35742.00000  38690.000000  59647.000000  40792.000000   \n","\n","                 61            65            66            63            64  \\\n","count   7129.000000   7129.000000   7129.000000   7129.000000   7129.000000   \n","mean     581.006593    556.054145    530.495020    727.593351    686.850610   \n","std     2467.740997   2360.238246   2463.108827   2488.340963   2703.734409   \n","min   -16268.000000 -14244.000000  -7626.000000 -20782.000000 -26258.000000   \n","25%      -36.000000    -31.000000    -15.000000    -21.000000    -51.000000   \n","50%      117.000000     99.000000     73.000000    162.000000    195.000000   \n","75%      422.000000    366.000000    280.000000    578.000000    683.000000   \n","max    37374.000000  27447.000000  53204.000000  31585.000000  71369.000000   \n","\n","                62  \n","count   7129.00000  \n","mean     671.16496  \n","std     2659.95898  \n","min   -11973.00000  \n","25%      -20.00000  \n","50%      136.00000  \n","75%      474.00000  \n","max    48374.00000  \n","\n","[8 rows x 34 columns]\n"]}],"source":["print(\"train Information:\")\n","print(train.info())\n","\n","print(\"\\ntest Statistics:\")\n","print(test.describe())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"exxnA8LTXNut"},"source":["Exploratory Data Analysis (EDA):"]},{"cell_type":"markdown","metadata":{"id":"WiCygqL5bUkS"},"source":["כדי שיהיה לי יותר קל לעבוד עם הקובץ, אני רוצה למזג את 2 הקבצים. עלי לבדוק שבשתי העמודות הראשונה של שתי הקבצים המבטאים את הגנים-אכן זהות לחלוטין, ואז אוכל לצרף את החולים שבקובץ 2 אל קובץ 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1716795792144,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"FCfH7czm51OL","outputId":"5686ffdb-acd5-4fd5-c4f4-600230a72ac2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nunique_genes_part1 = gene_expression_part1[[\\'Gene Description\\', \\'Gene Accession Number\\']].copy()\\nunique_genes_part2 = gene_expression_part2[[\\'Gene Description\\', \\'Gene Accession Number\\']].copy()\\n\\n# Check if the unique sets of genes are the same\\nare_gene_sets_equal = unique_genes_part1.equals(unique_genes_part2)\\n\\nif are_gene_sets_equal:\\n    print(\"Both files have the same types of genes.\")\\nelse:\\n    print(\"The sets of genes in the two files are not the same.\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}],"source":["# Extract unique genes from both files\n","'''\n","unique_genes_part1 = gene_expression_part1[['Gene Description', 'Gene Accession Number']].copy()\n","unique_genes_part2 = gene_expression_part2[['Gene Description', 'Gene Accession Number']].copy()\n","\n","# Check if the unique sets of genes are the same\n","are_gene_sets_equal = unique_genes_part1.equals(unique_genes_part2)\n","\n","if are_gene_sets_equal:\n","    print(\"Both files have the same types of genes.\")\n","else:\n","    print(\"The sets of genes in the two files are not the same.\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"xhgPlAZYb8Fp"},"source":["כעת אבדוק איפה הם לא זהים"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lvurtzll7o0z","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1716795792144,"user_tz":-180,"elapsed":37,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"283f3fb9-0bd3-4d2c-bfda-dd516e89c9fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Find rows where the first two columns are not the same\\nmismatched_rows = gene_expression_part1.loc[~(gene_expression_part1.iloc[:, :2] == gene_expression_part2.iloc[:, :2]).all(axis=1)]\\n\\n# Display the mismatched rows\\nprint(\"Rows where the first two columns are not the same:\")\\nprint(mismatched_rows)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}],"source":["'''\n","# Find rows where the first two columns are not the same\n","mismatched_rows = gene_expression_part1.loc[~(gene_expression_part1.iloc[:, :2] == gene_expression_part2.iloc[:, :2]).all(axis=1)]\n","\n","# Display the mismatched rows\n","print(\"Rows where the first two columns are not the same:\")\n","print(mismatched_rows)'''\n"]},{"cell_type":"markdown","metadata":{"id":"5-UAxpiCgaka"},"source":["נבדוק באמצעות קוד זה אפה בדיוק האינדקסים לא זהים ובמה:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18_4n3zvb-s_","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1716795792144,"user_tz":-180,"elapsed":37,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"01997ab7-5e91-4f9a-b94f-d7c680761b6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nimport difflib\\n\\n# Display detailed comparison for each non-identical index\\nfor index in non_identical_indices:\\n    print(f\"\\nComparison for Index {index}:\")\\n\\n    # Extract the strings from the Series\\n    str1 = gene_expression_part1.loc[index, \\'Gene Description\\'] + \\' \\' + gene_expression_part1.loc[index, \\'Gene Accession Number\\']\\n    str2 = gene_expression_part2.loc[index, \\'Gene Description\\'] + \\' \\' + gene_expression_part2.loc[index, \\'Gene Accession Number\\']\\n\\n    # Using difflib to highlight the differences\\n    diff = difflib.unified_diff(\\n        str1,\\n        str2,\\n        lineterm=\\'\\', fromfile=\\'gene_expression_part1\\', tofile=\\'gene_expression_part2\\'\\n    )\\n\\n    # Print the differences\\n    for line in diff:\\n        print(line)\\n\\n    print(\"\\n\")\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}],"source":["'''\n","import difflib\n","\n","# Display detailed comparison for each non-identical index\n","for index in non_identical_indices:\n","    print(f\"\\nComparison for Index {index}:\")\n","\n","    # Extract the strings from the Series\n","    str1 = gene_expression_part1.loc[index, 'Gene Description'] + ' ' + gene_expression_part1.loc[index, 'Gene Accession Number']\n","    str2 = gene_expression_part2.loc[index, 'Gene Description'] + ' ' + gene_expression_part2.loc[index, 'Gene Accession Number']\n","\n","    # Using difflib to highlight the differences\n","    diff = difflib.unified_diff(\n","        str1,\n","        str2,\n","        lineterm='', fromfile='gene_expression_part1', tofile='gene_expression_part2'\n","    )\n","\n","    # Print the differences\n","    for line in diff:\n","        print(line)\n","\n","    print(\"\\n\")\n","    '''"]},{"cell_type":"markdown","metadata":{"id":"Q7rzaJaYgf4Q"},"source":["כפי שזה נראה, הם לא זהים רק במספר רווחים. לא קריטי להמשך הקוד, אבל ננקה את הדאטא בכל זאת:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1716795792144,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"Cr8n63SEeaaX","outputId":"bca3aedb-6dac-4e1b-80e0-d74b04695e2e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Remove extra spaces in \\'Gene Description\\' column for both files\\ngene_expression_part1[\\'Gene Description\\'] = gene_expression_part1[\\'Gene Description\\'].str.replace(r\\'\\\\s+\\', \\' \\', regex=True).str.strip()\\ngene_expression_part2[\\'Gene Description\\'] = gene_expression_part2[\\'Gene Description\\'].str.replace(r\\'\\\\s+\\', \\' \\', regex=True).str.strip()\\n\\n# Check if the unique sets of genes are the same after cleanup\\nunique_genes_part1 = gene_expression_part1[[\\'Gene Description\\', \\'Gene Accession Number\\']].drop_duplicates()\\nunique_genes_part2 = gene_expression_part2[[\\'Gene Description\\', \\'Gene Accession Number\\']].drop_duplicates()\\n\\nare_gene_sets_equal_after_cleanup = unique_genes_part1.equals(unique_genes_part2)\\n\\nif are_gene_sets_equal_after_cleanup:\\n    print(\"Both files have the same types of genes after cleanup.\")\\nelse:\\n    print(\"The sets of genes in the two files are not the same after cleanup.\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}],"source":["'''\n","# Remove extra spaces in 'Gene Description' column for both files\n","gene_expression_part1['Gene Description'] = gene_expression_part1['Gene Description'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n","gene_expression_part2['Gene Description'] = gene_expression_part2['Gene Description'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n","\n","# Check if the unique sets of genes are the same after cleanup\n","unique_genes_part1 = gene_expression_part1[['Gene Description', 'Gene Accession Number']].drop_duplicates()\n","unique_genes_part2 = gene_expression_part2[['Gene Description', 'Gene Accession Number']].drop_duplicates()\n","\n","are_gene_sets_equal_after_cleanup = unique_genes_part1.equals(unique_genes_part2)\n","\n","if are_gene_sets_equal_after_cleanup:\n","    print(\"Both files have the same types of genes after cleanup.\")\n","else:\n","    print(\"The sets of genes in the two files are not the same after cleanup.\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"PZJwArqVhA40"},"source":["עכשיו נבדוק שוב עם העמודות זהות:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1716795792145,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"EUz--7R7g8W6","outputId":"33132756-9c8e-4faa-f2c9-0b2fa4b9613c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Extract unique genes from both files\\nunique_genes_part1 = gene_expression_part1[[\\'Gene Description\\', \\'Gene Accession Number\\']].copy()\\nunique_genes_part2 = gene_expression_part2[[\\'Gene Description\\', \\'Gene Accession Number\\']].copy()\\n\\n# Check if the unique sets of genes are the same\\nare_gene_sets_equal = unique_genes_part1.equals(unique_genes_part2)\\n\\nif are_gene_sets_equal:\\n    print(\"Both files have the same types of genes.\")\\nelse:\\n    print(\"The sets of genes in the two files are not the same.\")\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}],"source":["'''# Extract unique genes from both files\n","unique_genes_part1 = gene_expression_part1[['Gene Description', 'Gene Accession Number']].copy()\n","unique_genes_part2 = gene_expression_part2[['Gene Description', 'Gene Accession Number']].copy()\n","\n","# Check if the unique sets of genes are the same\n","are_gene_sets_equal = unique_genes_part1.equals(unique_genes_part2)\n","\n","if are_gene_sets_equal:\n","    print(\"Both files have the same types of genes.\")\n","else:\n","    print(\"The sets of genes in the two files are not the same.\")\n","    '''"]},{"cell_type":"markdown","metadata":{"id":"Muh8Tcslh91H"},"source":["כעת, נמז את שני הקבצים ונוריד את הקובץ החדש"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1716795792146,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"},"user_tz":-180},"id":"E8JQYFkWhDuf","outputId":"60289924-2249-4268-9dde-caff8ba4fc8e","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# Exclude the first two columns from the second file\\ngene_expression_part2_subset = gene_expression_part2.iloc[:, 2:].copy()\\n\\n# Merge the two files\\nmerged_gene_expression = pd.concat([gene_expression_part1, gene_expression_part2_subset], axis=1)\\n\\n# Save the merged dataframe to a CSV file\\nmerged_gene_expression.to_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/merged_gene_expression.csv', index=False)\\nall_data=pd.read_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/merged_gene_expression.csv')\\nprint(all_data.columns)\\nprint(all_data.head)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}],"source":["'''\n","# Exclude the first two columns from the second file\n","gene_expression_part2_subset = gene_expression_part2.iloc[:, 2:].copy()\n","\n","# Merge the two files\n","merged_gene_expression = pd.concat([gene_expression_part1, gene_expression_part2_subset], axis=1)\n","\n","# Save the merged dataframe to a CSV file\n","merged_gene_expression.to_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/merged_gene_expression.csv', index=False)\n","all_data=pd.read_csv('/content/drive/MyDrive/מיני פרוייקט לוקמיה/merged_gene_expression.csv')\n","print(all_data.columns)\n","print(all_data.head)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"RyxZPNtMiZ4O"},"source":["נבדוק כמה חולי AML וכמה חולי ALL יש לנו בדאטא"]},{"cell_type":"code","source":["y['cancer'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"collapsed":true,"id":"_8X1L5wt8wBK","executionInfo":{"status":"error","timestamp":1716795805901,"user_tz":-180,"elapsed":328,"user":{"displayName":"Tehilla Mosh","userId":"03307831208106892920"}},"outputId":"bc7d6512-ae78-4b61-a648-492317c8ffcc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'cancer'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'cancer'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-64e85bdeea2b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cancer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'cancer'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mk9GBlRFbRZR","collapsed":true},"outputs":[],"source":["# EDA for Cancer Mapping\n","sns.countplot(data=y, x='cancer')\n","plt.title('Distribution of Cancer Types')\n","plt.show()\n"]},{"cell_type":"markdown","source":["נעביר את הערכים לערכים נומרים בy"],"metadata":{"id":"wweXT0c783ZW"}},{"cell_type":"code","source":["# Recode label to numeric\n","y = y.replace({'ALL':0,'AML':1})\n","labels = ['ALL', 'AML']"],"metadata":{"id":"08I8XO1f885r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["עכשיו נעבור לנתונים של החולים"],"metadata":{"id":"qmS-PzKS9Var"}},{"cell_type":"code","source":["print(train.shape)\n","print(test.shape)"],"metadata":{"id":"YAMZsNR99fbF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"mOX3scqI9rnj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.head()"],"metadata":{"id":"dhhRgGJv9vAz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["השמות של העמודות לא בסדר מספרי, נסדר אותם"],"metadata":{"id":"arGMKvTa_e3U"}},{"cell_type":"code","source":["train_columns_titles = ['Gene Description', 'Gene Accession Number', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n","       '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25',\n","       '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38']\n","\n","train =train.reindex(columns=train_columns_titles)"],"metadata":{"id":"at5XhUVD_kHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"collapsed":true,"id":"ufm8sWEdCPFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_columns_titles = ['Gene Description', 'Gene Accession Number','39', '40', '41', '42', '43', '44', '45', '46',\n","       '47', '48', '49', '50', '51', '52', '53',  '54', '55', '56', '57', '58', '59',\n","       '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72']\n","\n","test = test.reindex(columns=test_columns_titles)"],"metadata":{"id":"P1M6jtJrCYtn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.head()"],"metadata":{"collapsed":true,"id":"cDgxvaJLCd2y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["נחליף בין השורות לעמודות, כדי שהתכונות יהיו בעמודות וזה יקל עלינו לבצע הורדת מימדים ואימון המודל"],"metadata":{"id":"FGY6K-CNIcka"}},{"cell_type":"code","source":["X_train = train.T\n","X_test = test.T\n","\n","print(X_train.shape)\n","X_train.head()"],"metadata":{"id":"bLeL1ed9Iiqz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["נהפוך את השורה השנייה לשמות העמודות ונמחק את הראשונה, אני רואה ששתי השורות פשוט כפיליות אחת של השנייה"],"metadata":{"id":"0s7gfoayJ5Yb"}},{"cell_type":"code","source":["# Clean up the column names for training data\n","X_train.columns = X_train.iloc[1]\n","# Set column names of X_train to the values in the second row of X_train.\n","\n","X_train = X_train.drop([\"Gene Description\", \"Gene Accession Number\"]).apply(pd.to_numeric)\n","# Drop columns 'Gene Description' and 'Gene Accession Number' from X_train and convert the remaining columns to numeric.\n","\n","# Clean up the column names for Testing data\n","X_test.columns = X_test.iloc[1]\n","# Set column names of X_test to the values in the second row of X_test.\n","\n","X_test = X_test.drop([\"Gene Description\", \"Gene Accession Number\"]).apply(pd.to_numeric)\n","# Drop columns 'Gene Description' and 'Gene Accession Number' from X_test and convert the remaining columns to numeric.\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","X_train.head()\n","# Print the shape of X_train and X_test and display the first few rows of X_train.\n"],"metadata":{"collapsed":true,"id":"QXGm1Vn4KDcO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["עכשיו נתאים את התוויות של המטפולים לנתונים"],"metadata":{"id":"QENHxnk-Q9x0"}},{"cell_type":"code","source":["print(y)"],"metadata":{"collapsed":true,"id":"v0NSo0b1TCwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Split into train and test (we first need to reset the index as the indexes of two dataframes need to be the same before you combine them).\n","\"\"\"\n","# Convert 'patient' column to integers\n","y[\"patient\"] = y[\"patient\"].astype(int)\n","\n","# Reset index for X_train and y_train\n","X_train = X_train.reset_index(drop=True)\n","# Reset the index of X_train dataframe and drop the previous index.\n","\n","# חלוקה נכונה של הנתונים וה-labels\n","y_train = y[y.patient <= 38]['cancer'].reset_index(drop=True)\n","\n","\n","# Subset the labels (y) for the first 38 patients and reset index, dropping the previous index.\n","\n","# Reset index for X_test and y_test\n","X_test = X_test.reset_index(drop=True)\n","# Reset the index of X_test dataframe and drop the previous index.\n","\n","y_test = y[y.patient > 38]['cancer'].reset_index(drop=True)\n","# Subset the labels (y) for the patients after the first 38 and reset index, dropping the previous index.\n"],"metadata":{"id":"ipw4z9BnRBj2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["נבדוק איך התקדמנו"],"metadata":{"id":"r9f77gJiUC2m"}},{"cell_type":"code","source":["X_train.describe()"],"metadata":{"id":"rIUggWEQUGdj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ניתן לראות שהתכונות אינם באותו קנה מידה, וזה יכול להזיק לטסט., ננסה לנרמל את הנתונים"],"metadata":{"id":"_TpR1VcLVfAv"}},{"cell_type":"markdown","source":["הבלוק הזה מבצע את השלבים הבאים:\n","\n","1. **המרת סוג הנתונים:** בשלב הראשון, נתוני האימון והבדיקה מומרות מסוג integer לסוג float עם דיוק של 64 ביט. זה מבטיח חישובים מדויקים יותר בתהליך הסטנדרטיזציה.\n","\n","2. **סטנדרטיזציה:** לאחר מכן, יוצרים אובייקט מסוג `StandardScaler` שמבצע סטנדרטיזציה על הנתונים. בתהליך זה, נתוני האימון מתאימים ומתמרים, כלומר מחשבים את הממוצע והשונות של כל תכונה בנתונים ולאחר מכן מבצעים את הסטנדרטיזציה כך שכל תכונה תהיה בעלת ממוצע של 0 ושונות של 1.\n","\n","3. **התמרת נתוני הבדיקה:** לבסוף, מתמרים את נתוני הבדיקה על פי הממוצע והשונות שחושבו מנתוני האימון, כדי לשמור על עקביות בין סט הנתונים של האימון והבדיקה."],"metadata":{"id":"6Hk51lapZJOV"}},{"cell_type":"code","source":["# Convert from integer to float\n","# המרה של הנתונים מסוג integer ל-float עם דיוק של 64 ביט\n","X_train_fl = X_train.astype(float, 64)  # המרה של נתוני האימון ל-float\n","X_test_fl = X_test.astype(float, 64)    # המרה של נתוני הבדיקה ל-float\n","\n","# Apply the same scaling to both datasets\n","# יצירת אובייקט StandardScaler שיבצע סטנדרטיזציה לנתונים\n","scaler = StandardScaler()\n","\n","# סטנדרטיזציה של נתוני האימון על ידי התאמה והתמרה של הנתונים\n","# 1. fit: חישוב הממוצע והשונות של כל תכונה בנתוני האימון\n","# 2. transform: התמרת הנתונים כך שיהיו בעלי ממוצע של 0 ושונות של 1\n","X_train_scl = scaler.fit_transform(X_train_fl)\n","\n","# התמרה של נתוני הבדיקה על פי ההתאמה של נתוני האימון\n","# (כדי לשמור על עקביות בין סט הנתונים של האימון וסט הנתונים של הבדיקה)\n","# transform: התמרת נתוני הבדיקה על פי הממוצע והשונות שחושבו מנתוני האימון\n","X_test_scl = scaler.transform(X_test_fl) # שים לב שאנחנו משתמשים ב-transform ולא ב-fit_transform\n"],"metadata":{"id":"oj5mosV9YBFx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["נבצע PCA"],"metadata":{"id":"K-73YVQ_ZyyI"}},{"cell_type":"code","source":["# Import the PCA module from sklearn\n","from sklearn.decomposition import PCA\n","\n","# Create a PCA object without specifying the number of components\n","pca = PCA()\n","\n","# Fit the PCA model to the training data and transform the data\n","# This step computes the principal components and reduces the dimensionality of the training data\n","X_train_pca = pca.fit_transform(X_train_scl)\n","\n","# Apply the same transformation to the test data\n","# This ensures that the test data is reduced to the same principal components as the training data\n","X_test_pca = pca.transform(X_test_scl)\n"],"metadata":{"id":"tk8oNd3UZ0rP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's set a threshold for explained variance of 90% and see how many features are required to meet that threshold"],"metadata":{"id":"PBW7GQNjapNK"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","\n","# Convert from integer to float and scale the data\n","X_train_fl = X_train.astype(float, 64)\n","X_test_fl = X_test.astype(float, 64)\n","scaler = StandardScaler()\n","X_train_scl = scaler.fit_transform(X_train_fl)\n","X_test_scl = scaler.transform(X_test_fl)\n","\n","# Create a PCA object and fit it to the training data\n","pca = PCA()\n","X_train_pca = pca.fit_transform(X_train_scl)\n","\n","# Calculate the total variance\n","total = sum(pca.explained_variance_)\n","k = 0\n","current_variance = 0\n","\n","# Find the number of components that explain 90% of the variance\n","while current_variance / total < 0.90:\n","    current_variance += pca.explained_variance_[k]\n","    k += 1\n","\n","# Print the number of components needed\n","print(k, \" features explain around 90% of the variance. From 7129 features to \"  ,sep='')\n","\n","# Fit PCA again with the optimal number of components\n","pca = PCA(n_components=k)\n","X_train_pca = pca.fit_transform(X_train_scl)\n","X_test_pca = pca.transform(X_test_scl)\n","\n","# Calculate cumulative explained variance for visualization\n","var_exp = pca.explained_variance_ratio_.cumsum()\n","var_exp = var_exp * 100\n","\n","# Plot cumulative explained variance\n","plt.bar(range(k), var_exp)\n","plt.xlabel('Number of Principal Components')\n","plt.ylabel('Cumulative Explained Variance (%)')\n","plt.title('Explained Variance by Principal Components')\n","plt.show()\n"],"metadata":{"id":"uJIB5WIUajUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["המרת נתונים ל-float וסטנדרטיזציה:\n","\n","כדי להבטיח חישובים מדויקים יותר, המרה של כל הנתונים ל-float וסטנדרטיזציה שלהם כך שיהיו בעלי ממוצע של 0 ושונות של 1.\n","חישוב רכיבים עיקריים (PCA):\n","\n","שימוש ב-PCA כדי להפחית את המימדים של הנתונים על ידי חישוב רכיבים עיקריים שמסבירים את מרבית השונות בנתונים.\n","בחירת מספר הרכיבים האופטימלי:\n","\n","איתור מספר הרכיבים המינימלי שמסביר 90% מהשונות הכוללת כדי לצמצם את מספר המימדים תוך שמירה על מרבית המידע.\n","התאמה והתמרה של הנתונים מחדש:\n","\n","התאמה מחדש של מודל ה-PCA עם מספר הרכיבים האופטימלי והתמרה של נתוני האימון והבדיקה.\n","הצגת השונות המוסברת:\n","\n","הצגת השונות המוסברת המצטברת באמצעות גרף ברים כדי להמחיש את תרומת כל רכיב עיקרי לשונות הכוללת."],"metadata":{"id":"_9Oc3T9Faa0H"}},{"cell_type":"markdown","source":["יצירת אוטואינקודר:\n","\n","אוטואינקודר הוא רשת עצבית המורכבת משני חלקים: מקודד ודקודר. המקודד מצמצם את מימדי הקלט, והדקודר מנסה לשחזר את הקלט המקורי מהייצוג המצומצם.\n","אימון האוטואינקודר:\n","\n","מאמנים את האוטואינקודר על נתוני האימון.\n","התמרת הנתונים לייצוג מצומצם:\n","\n","משתמשים במקודד כדי להמיר את הנתונים לייצוג המצומצם."],"metadata":{"id":"1bCfD8cYbpgg"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from sklearn.preprocessing import StandardScaler\n","\n","# Convert from integer to float and scale the data\n","X_train_fl = X_train.astype(float, 64)  # המרה של נתוני האימון ל-float\n","X_test_fl = X_test.astype(float, 64)    # המרה של נתוני הבדיקה ל-float\n","scaler = StandardScaler()  # יצירת אובייקט StandardScaler\n","X_train_scl = scaler.fit_transform(X_train_fl)  # סטנדרטיזציה של נתוני האימון\n","X_test_scl = scaler.transform(X_test_fl)  # סטנדרטיזציה של נתוני הבדיקה\n","\n","# Apply PCA to reduce dimensions before using the autoencoder\n","pca = PCA()\n","X_train_pca = pca.fit_transform(X_train_scl)\n","X_test_pca = pca.transform(X_test_scl)\n","\n","# Calculate the total variance and find the number of components that explain 90% of the variance\n","total = sum(pca.explained_variance_)\n","k = 0\n","current_variance = 0\n","\n","while current_variance / total < 0.90:\n","    current_variance += pca.explained_variance_[k]\n","    k += 1\n","\n","print(k, \" features explain around 90% of the variance. From 7129 features to \", k, \", not too bad.\", sep='')\n","\n","pca = PCA(n_components=k)\n","X_train_pca = pca.fit_transform(X_train_scl)\n","X_test_pca = pca.transform(X_test_scl)\n","\n","# Define the size of the encoding (dimensionality reduction target)\n","encoding_dim = 50  # for example, reduce to 50 dimensions\n","\n","# Input placeholder\n","input_data = Input(shape=(X_train_pca.shape[1],))  # כניסת הנתונים לאוטואינקודר בגודל של מספר הרכיבים לאחר PCA\n","\n","# Encoded representation of the input\n","encoded = Dense(encoding_dim, activation='relu')(input_data)  # שכבת קידוד שמצמצמת את המימדים ל-50\n","\n","# Reconstruction of the input\n","decoded = Dense(X_train_pca.shape[1], activation='sigmoid')(encoded)  # שכבת דקודינג שמשחזרת את הקלט המקורי\n","\n","# Model that maps an input to its reconstruction\n","autoencoder = Model(input_data, decoded)  # יצירת מודל האוטואינקודר\n","\n","# Model that maps an input to its encoded representation\n","encoder = Model(input_data, encoded)  # יצירת מודל המקודד (encoder) בלבד\n","\n","# Compile the autoencoder\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')  # קומפילציה של מודל האוטואינקודר עם אופטימייזר adam ופונקציית הפסד MSE\n","\n","# Train the autoencoder\n","autoencoder.fit(X_train_pca, X_train_pca,\n","                epochs=50,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_test_pca, X_test_pca))  # אימון האוטואינקודר על נתוני האימון עם אימות על נתוני הבדיקה\n","\n","# Encode the training and test data\n","X_train_encoded = encoder.predict(X_train_pca)  # קידוד נתוני האימון לייצוג מצומצם\n","X_test_encoded = encoder.predict(X_test_pca)  # קידוד נתוני הבדיקה לייצוג מצומצם\n"],"metadata":{"id":"0qSocagScCln"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["תחילה מבצעים המרה וסטנדרטיזציה לנתונים.\n","לאחר מכן מבצעים PCA לצמצום מימדים ושומרים רק את הרכיבים שמסבירים 90% מהשונות.\n","בונים אוטואינקודר עם שכבת קידוד שמצמצמת עוד יותר את המימדים ושכבת דקודינג שמשחזרת את הקלט.\n","מאמנים את האוטואינקודר על הנתונים ולאחר מכן משתמשים במקודד כדי להמיר את הנתונים לייצוג המצומצם."],"metadata":{"id":"aLnJNzmlcTmq"}},{"cell_type":"markdown","source":["CA:\n","\n","פשטות ומהירות: PCA היא שיטה מהירה יחסית ופשוטה להבנה ולביצוע. היא מבוססת על אלגוריתמים מתמטיים שמבצעים פירוק ערכים סינגולריים (SVD).\n","שימור שונות מקסימלית: PCA מבטיחה שכל רכיב עיקרי חדש מסביר את המקסימום האפשרי של השונות בנתונים.\n","אוטואינקודר:\n","\n","יכולת למידה לא לינארית: בניגוד ל-PCA, אוטואינקודרים יכולים ללמוד קשרים לא לינאריים בנתונים. זה חשוב במיוחד כאשר הנתונים מורכבים ומכילים קשרים לא לינאריים רבים.\n","גמישות: אוטואינקודרים הם רשתות נוירונים שניתן להגדיר ולהתאים לצרכים שונים של הנתונים והתכונות.\n","השימוש המשולב:\n","השימוש ב-PCA לפני אוטואינקודר יכול להועיל במצבים מסוימים:\n","\n","הפחתת רעש והקטנת מורכבות: PCA יכול לסייע בהפחתת רעש ובצמצום מימדים ראשוני, מה שמקטין את כמות הנתונים שהאוטואינקודר צריך לטפל בהם.\n","שיפור ביצועים: על ידי צמצום מימדים ראשוני עם PCA, האוטואינקודר יכול להתמקד בלמידת תכונות מורכבות יותר בנתונים שנותרו.\n","זמן אימון קצר יותר: על ידי צמצום מימדים עם PCA, זמן האימון של האוטואינקודר עשוי להיות קצר יותר, מכיוון שהוא מתמודד עם פחות נתונים."],"metadata":{"id":"c0goHikvdCcf"}},{"cell_type":"markdown","source":["MODELS"],"metadata":{"id":"k7cgAaW_gWir"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvccwZ8eWKh0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Set the style of seaborn\n","sns.set(style=\"whitegrid\")\n","\n","# Convert patient IDs to integers\n","all_patients = [int(patient) for patient in all_patients]\n","aml_patients = [int(patient) for patient in aml_patients]\n","\n","# Check if all patient IDs are present in columns\n","all_patients_present = all(pat in merged_gene_expression.columns for pat in all_patients)\n","aml_patients_present = all(pat in merged_gene_expression.columns for pat in aml_patients)\n","\n","if all_patients_present and aml_patients_present:\n","    # Extract ALL and AML data\n","    all_data = merged_gene_expression.loc[:, all_patients].transpose()\n","    aml_data = merged_gene_expression.loc[:, aml_patients].transpose()\n","\n","    # Select the first two genes\n","    selected_genes_for_boxplot = all_data.columns[:2]\n","\n","    # Plot boxplot for the selected genes\n","    plt.figure(figsize=(10, 6))\n","    sns.boxplot(x=\"Gene\", y=\"Expression Level\", hue=\"Patient Type\",\n","                data=pd.concat([all_data[selected_genes_for_boxplot].melt(value_name='Expression Level', var_name='Gene', ignore_index=False),\n","                                aml_data[selected_genes_for_boxplot].melt(value_name='Expression Level', var_name='Gene', ignore_index=False)]),\n","                palette=\"Set3\")\n","\n","    plt.title('Boxplot of Gene Expression Levels for AML and ALL Patients')\n","    plt.xlabel('Gene')\n","    plt.ylabel('Expression Level')\n","    plt.legend(title='Patient Type')\n","    plt.show()\n","else:\n","    print(\"Patient IDs not present in columns.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIkgxLxrgasu","collapsed":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Assuming 'all_data' is your DataFrame containing gene expression data\n","\n","# Select genes in groups of 5\n","for i in range(0, len(all_data.columns), 5):\n","    selected_genes_for_boxplot = all_data.columns[i:i+5]\n","\n","    # Create a smaller boxplot for the selected genes\n","    plt.figure(figsize=(8, 4))\n","    all_data[selected_genes_for_boxplot].boxplot()\n","\n","    plt.title(f'Boxplot of Gene Expression Levels (Genes {i+1} to {i+5})')\n","    plt.xlabel('Genes')\n","    plt.ylabel('Expression Level')\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGnbgEacEXLC","collapsed":true},"outputs":[],"source":["\n","# Boxplot for a few genes\n","selected_genes_for_boxplot = all_data.columns[7:15]\n","all_data[selected_genes_for_boxplot].boxplot()\n","plt.title('Boxplot of Gene Expression Levels')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osb6YDhRnMtR"},"outputs":[],"source":["# Identifying outliers using Z-score\n","from scipy.stats import zscore\n","\n","# Exclude non-numeric columns\n","numeric_columns = all_data.columns[all_data.columns.str.isnumeric()]\n","\n","# Calculate Z-scores for each numeric column\n","z_scores = zscore(all_data[numeric_columns])\n","\n","# Define a threshold for identifying outliers\n","z_threshold = 3\n","\n","# Find indices of outliers\n","outlier_indices = np.where(np.abs(z_scores) > z_threshold)\n","\n","# Display the indices of outliers\n","print(\"Indices of Outliers:\")\n","print(outlier_indices)\n","\n","\n"]},{"cell_type":"markdown","source":["MODELS"],"metadata":{"id":"y615lQ29i8hx"}},{"cell_type":"markdown","source":["וד להקמת מודל Gradient Boosting עם כיוונון היפר-פרמטרים והערכת ביצועים:"],"metadata":{"id":"Mfmfr2I3i_Nr"}},{"cell_type":"code","source":["print(f\"Number of samples in X_train_encoded: {X_train_encoded.shape[0]}\")\n","print(f\"Number of samples in y_train: {y_train.shape[0]}\")\n"],"metadata":{"id":"TIhAJImnkEqv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","# בדיקת מספר הדוגמאות כדי לוודא שהתאמתם נכונה\n","print(f\"Number of samples in X_train_encoded: {X_train_encoded.shape[0]}\")\n","print(f\"Number of samples in y_train: {y_train.shape[0]}\")\n","print(f\"Number of samples in X_test_encoded: {X_test_encoded.shape[0]}\")\n","print(f\"Number of samples in y_test: {y_test.shape[0]}\")\n","\n","# המרה של y_train ו-y_test לחד-ממדי במידת הצורך\n","y_train = y_train.ravel()  # המרה לחד-ממדי אם הם לא כאלה כבר\n","y_test = y_test.ravel()    # המרה לחד-ממדי אם הם לא כאלה כבר\n","\n","# הגדרת המסווג והיפר-פרמטרים לבדיקת GridSearchCV\n","gbc = GradientBoostingClassifier()\n","param_grid = {\n","    'n_estimators': [50, 100, 150],   # מספר העצים ביער\n","    'learning_rate': [0.01, 0.1, 0.2],  # קצב הלמידה\n","    'max_depth': [3, 4, 5]  # עומק מרבי של כל עץ\n","}\n","\n","# כיוונון היפר-פרמטרים עם GridSearchCV\n","grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', error_score='raise')\n","grid_search.fit(X_train_encoded, y_train)\n","\n","# קבלת התוצאות הטובות ביותר מה-GridSearchCV\n","best_params = grid_search.best_params_\n","best_model = grid_search.best_estimator_\n","\n","print(f\"Best parameters found: {best_params}\")\n","\n","# ביצוע Cross-Validation להערכת הביצועים של המודל הטוב ביותר\n","cv_scores = cross_val_score(best_model, X_train_encoded, y_train, cv=5, scoring='accuracy')\n","print(f\"Cross-Validation Scores: {cv_scores}\")\n","print(f\"Mean CV Accuracy: {np.mean(cv_scores)}\")\n","\n","# אימון המודל הטוב ביותר על כל נתוני האימון\n","best_model.fit(X_train_encoded, y_train)\n","\n","# ניבוי על נתוני הבדיקה\n","y_pred = best_model.predict(X_test_encoded)\n","\n","# הערכת ביצועים\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(f\"Test Accuracy: {accuracy}\")\n","print(f\"Classification Report:\\n{report}\")\n"],"metadata":{"id":"wVH7wjOZjBHl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["במהלך תהליך האימון של המודל לסיווג סוגי הלוקמיה (AML ו-ALL), נתקלנו במספר בעיות וטעויות. הנה סיכום של הבעיות והפתרונות שהוצעו:\n","\n","### 1. חוסר התאמה בין מספר הדוגמאות ב-X ו-y:\n","**בעיה:** מספר הדוגמאות ב-X_train_encoded לא התאים למספר הדוגמאות ב-y_train. זה גרם לשגיאת \"ValueError: Found input variables with inconsistent numbers of samples\".\n","\n","**פתרון:** וידאנו שהחלוקה הראשונית של הנתונים מתבצעת בצורה נכונה. תיקנו את החלוקה כך שמספר הדוגמאות ב-X וב-y יהיה תואם:\n","```python\n","y_train = y[y.patient <= 38]['cancer'].reset_index(drop=True)\n","y_test = y[y.patient > 38]['cancer'].reset_index(drop=True)\n","\n","assert X_train.shape[0] == y_train.shape[0], \"Mismatch in training data samples\"\n","assert X_test.shape[0] == y_test.shape[0], \"Mismatch in test data samples\"\n","```\n","\n","### 2. המרת ה-labels למערך חד-ממדי:\n","**בעיה:** כאשר ה-labels (התוויות) היו במבנה דו-ממדי, זה גרם לשגיאות במהלך האימון.\n","\n","**פתרון:** המרת ה-labels למערך חד-ממדי באמצעות `ravel`:\n","```python\n","y_train = y_train.values.ravel()\n","y_test = y_test.values.ravel()\n","```\n","\n","### 3. בדיקת מספר הדוגמאות בכל סט:\n","**בעיה:** לא תמיד היה ברור אם מספר הדוגמאות בכל סט תואם.\n","\n","**פתרון:** הוספת הדפסות לבדיקה לוודא שמספר הדוגמאות תואם בין ה-DataFrame של התכונות וה-DataFrame של ה-labels:\n","```python\n","print(f\"Number of samples in X_train_encoded: {X_train_encoded.shape[0]}\")\n","print(f\"Number of samples in y_train: {y_train.shape[0]}\")\n","print(f\"Number of samples in X_test_encoded: {X_test_encoded.shape[0]}\")\n","print(f\"Number of samples in y_test: {y_test.shape[0]}\")\n","```\n","\n","### 4. סטנדרטיזציה והורדת מימדים:\n","**בעיה:** ערכי התכונות לא היו באותו קנה מידה, מה שעלול לפגוע בביצועי המודל.\n","\n","**פתרון:** ביצוע סטנדרטיזציה על הנתונים כדי להבטיח שכל התכונות יהיו בעלות ממוצע של 0 ושונות של 1:\n","```python\n","scaler = StandardScaler()\n","X_train_scl = scaler.fit_transform(X_train)\n","X_test_scl = scaler.transform(X_test)\n","```\n","\n","ביצוע PCA להורדת מימדים ושימוש באוטואינקודר להקטנת מימדים נוספים:\n","```python\n","pca = PCA()\n","X_train_pca = pca.fit_transform(X_train_scl)\n","X_test_pca = pca.transform(X_test_scl)\n","```\n","\n","### 5. אימון המודל:\n","**בעיה:** תהליך האימון עצמו דרש כיוונון היפר-פרמטרים ושימוש ב-Cross-Validation כדי להבטיח ביצועים מיטביים.\n","\n","**פתרון:** שימוש ב-GridSearchCV לכיוונון היפר-פרמטרים וביצוע Cross-Validation להערכת הביצועים של המודל הטוב ביותר:\n","```python\n","gbc = GradientBoostingClassifier()\n","param_grid = {\n","    'n_estimators': [50, 100, 150],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'max_depth': [3, 4, 5]\n","}\n","\n","grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', error_score='raise')\n","grid_search.fit(X_train_encoded, y_train)\n","\n","best_params = grid_search.best_params_\n","best_model = grid_search.best_estimator_\n","\n","cv_scores = cross_val_score(best_model, X_train_encoded, y_train, cv=5, scoring='accuracy')\n","print(f\"Cross-Validation Scores: {cv_scores}\")\n","print(f\"Mean CV Accuracy: {np.mean(cv_scores)}\")\n","```\n","\n","### סיכום:\n","על ידי פתרון בעיות ההתאמה בין התכונות והתוויות, המרת התוויות למבנה חד-ממדי, ביצוע סטנדרטיזציה והורדת מימדים, וכיוונון היפר-פרמטרים, הצלחנו להכין את הנתונים ולאמן מודל Gradient Boosting בצורה מיטבית. כל אחד מהשלבים הללו חיוני להבטחת ביצועים טובים של המודל על נתוני האימון והבדיקה."],"metadata":{"id":"U2ty69i2nmXE"}},{"cell_type":"markdown","source":["ניתוח התוצאות ואפשרויות לשיפור:\n","תוצאות האימון מצביעות על כך שהמודל שלנו לא מבצע סיווג בצורה אופטימלית, עם דיוק של 70.59% בלבד על סט הבדיקה. התוצאות מצביעות גם על כך שהמודל מצליח לסווג בצורה טובה יותר את המחלקה 0 (ALL) מאשר את המחלקה 1 (AML).\n","\n","ניתוח הדוח:\n","דיוק כללי (Accuracy): 70.59%\n","Precision עבור מחלקה 0: 0.67 (שיעור הדוגמאות שסווגו כ-0 שהן אכן 0)\n","Recall עבור מחלקה 0: 1.00 (שיעור הדוגמאות שהן 0 שסווגו נכון)\n","Precision עבור מחלקה 1: 1.00 (שיעור הדוגמאות שסווגו כ-1 שהן אכן 1)\n","Recall עבור מחלקה 1: 0.29 (שיעור הדוגמאות שהן 1 שסווגו נכון)\n","F1-Score עבור מחלקה 0 ו-1: מצביע על הביצועים המשולבים של precision ו-recall\n","אפשרויות לשיפור:\n","הוספת נתונים:\n","הגדלת כמות הדוגמאות יכולה לעזור למודל ללמוד טוב יותר את הנתונים ולהשתפר בביצועים.\n","שימוש בטכניקות עיבוד נתונים נוספות:\n","ייתכן שניתן לשפר את הביצועים באמצעות הנדסת תכונות (Feature Engineering) נוספת, כמו יצירת תכונות חדשות או הסרת תכונות שאינן רלוונטיות.\n","איזון הנתונים:\n","ייתכן שהנתונים אינם מאוזנים, כלומר יש יותר דוגמאות של מחלקה אחת מאשר של מחלקה אחרת. ניתן להשתמש בטכניקות כמו SMOTE ליצירת דוגמאות חדשות למחלקה הפחות נפוצה.\n","ניסיון עם מודלים נוספים:\n","ניתן לנסות מודלים נוספים כמו Random Forest, SVM או Neural Networks ולראות אם הם מצליחים טוב יותר.\n","כיוונון היפר-פרמטרים נוסף:\n","ניתן לנסות ערכים נוספים להיפר-פרמטרים של המודל ולהרחיב את החיפוש כדי למצוא את השילוב האופטימלי."],"metadata":{"id":"XwJ6GHTPn7lo"}},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"-FwjACbyoCCx"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# הגדרת המסווג והיפר-פרמטרים לבדיקת GridSearchCV\n","rfc = RandomForestClassifier()\n","param_grid_rf = {\n","    'n_estimators': [50, 100, 150],   # מספר העצים ביער\n","    'max_depth': [3, 4, 5, None],     # עומק מרבי של כל עץ\n","    'min_samples_split': [2, 5, 10],  # מינימום דוגמאות לפיצול צומת\n","    'min_samples_leaf': [1, 2, 4]     # מינימום דוגמאות לעלה\n","}\n","\n","# כיוונון היפר-פרמטרים עם GridSearchCV\n","grid_search_rf = GridSearchCV(estimator=rfc, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='accuracy', error_score='raise')\n","grid_search_rf.fit(X_train_encoded, y_train)\n","\n","# קבלת התוצאות הטובות ביותר מה-GridSearchCV\n","best_params_rf = grid_search_rf.best_params_\n","best_model_rf = grid_search_rf.best_estimator_\n","\n","print(f\"Best parameters found for Random Forest: {best_params_rf}\")\n","\n","# ביצוע Cross-Validation להערכת הביצועים של המודל הטוב ביותר\n","cv_scores_rf = cross_val_score(best_model_rf, X_train_encoded, y_train, cv=5, scoring='accuracy')\n","print(f\"Cross-Validation Scores for Random Forest: {cv_scores_rf}\")\n","print(f\"Mean CV Accuracy for Random Forest: {np.mean(cv_scores_rf)}\")\n","\n","# אימון המודל הטוב ביותר על כל נתוני האימון\n","best_model_rf.fit(X_train_encoded, y_train)\n","\n","# ניבוי על נתוני הבדיקה\n","y_pred_rf = best_model_rf.predict(X_test_encoded)\n","\n","# הערכת ביצועים\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","report_rf = classification_report(y_test, y_pred_rf)\n","\n","print(f\"Test Accuracy for Random Forest: {accuracy_rf}\")\n","print(f\"Classification Report for Random Forest:\\n{report_rf}\")\n"],"metadata":{"id":"hhfBu55AjKcq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ניתוח תוצאות Random Forest ואפשרויות לשיפור:\n","\n","תוצאות האימון של המודל Random Forest מראות שיפור בביצועים בהשוואה ל-Gradient Boosting, אך עדיין יש בעיות דומות בזיהוי המחלקה 1 (AML).\n","\n","### תוצאות Random Forest:\n","- **דיוק כללי (Accuracy):** 67.65%\n","- **Precision עבור מחלקה 0:** 0.65 (שיעור הדוגמאות שסווגו כ-0 שהן אכן 0)\n","- **Recall עבור מחלקה 0:** 1.00 (שיעור הדוגמאות שהן 0 שסווגו נכון)\n","- **Precision עבור מחלקה 1:** 1.00 (שיעור הדוגמאות שסווגו כ-1 שהן אכן 1)\n","- **Recall עבור מחלקה 1:** 0.21 (שיעור הדוגמאות שהן 1 שסווגו נכון)\n","- **F1-Score עבור מחלקה 0 ו-1:** מצביע על הביצועים המשולבים של precision ו-recall\n","\n","### אפשרויות לשיפור:\n","1. **איזון הנתונים:**\n","   - הנתונים עשויים להיות בלתי מאוזנים. יש יותר דוגמאות ממחלקה אחת לעומת המחלקה השנייה. ניתן להשתמש בטכניקות כמו SMOTE ליצירת דוגמאות חדשות למחלקה הפחות נפוצה.\n","\n","2. **שימוש בטכניקות עיבוד נתונים נוספות:**\n","   - הנדסת תכונות נוספת יכולה לשפר את ביצועי המודל. ניתן לבדוק הוספת תכונות חדשות או הסרת תכונות שאינן רלוונטיות.\n","\n","3. **ניסיון עם מודלים נוספים:**\n","   - ייתכן שניתן להשיג שיפור בביצועים באמצעות מודלים נוספים כמו SVM או Neural Networks.\n","\n","4. **שילוב מודלים (Ensemble Learning):**\n","   - ניתן לשקול שימוש בטכניקות של למידת מכונה משולבת (Ensemble Learning) כמו Voting Classifier לשילוב התוצאות של מספר מודלים.\n","\n","5. **כיול המודל (Model Calibration):**\n","   - כיוון המודל על מנת לשפר את הדיוק בהערכת ההסתברויות לסיווגים השונים.\n","\n","### ניסוי עם SMOTE לאיזון הנתונים:\n","\n","\n"],"metadata":{"id":"xpGpe4jNoyjq"}},{"cell_type":"code","source":["\n","from imblearn.over_sampling import SMOTE\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# יישום SMOTE לאיזון הנתונים\n","smote = SMOTE(random_state=42)\n","X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded, y_train)\n","\n","# הגדרת המסווג והיפר-פרמטרים לבדיקת GridSearchCV\n","rfc = RandomForestClassifier()\n","param_grid_rf = {\n","    'n_estimators': [50, 100, 150],   # מספר העצים ביער\n","    'max_depth': [3, 4, 5, None],     # עומק מרבי של כל עץ\n","    'min_samples_split': [2, 5, 10],  # מינימום דוגמאות לפיצול צומת\n","    'min_samples_leaf': [1, 2, 4]     # מינימום דוגמאות לעלה\n","}\n","\n","# כיוונון היפר-פרמטרים עם GridSearchCV\n","grid_search_rf = GridSearchCV(estimator=rfc, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='accuracy', error_score='raise')\n","grid_search_rf.fit(X_train_balanced, y_train_balanced)\n","\n","# קבלת התוצאות הטובות ביותר מה-GridSearchCV\n","best_params_rf = grid_search_rf.best_params_\n","best_model_rf = grid_search_rf.best_estimator_\n","\n","print(f\"Best parameters found for Random Forest with SMOTE: {best_params_rf}\")\n","\n","# ביצוע Cross-Validation להערכת הביצועים של המודל הטוב ביותר\n","cv_scores_rf = cross_val_score(best_model_rf, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy')\n","print(f\"Cross-Validation Scores for Random Forest with SMOTE: {cv_scores_rf}\")\n","print(f\"Mean CV Accuracy for Random Forest with SMOTE: {np.mean(cv_scores_rf)}\")\n","\n","# אימון המודל הטוב ביותר על כל נתוני האימון\n","best_model_rf.fit(X_train_balanced, y_train_balanced)\n","\n","# ניבוי על נתוני הבדיקה\n","y_pred_rf = best_model_rf.predict(X_test_encoded)\n","\n","# הערכת ביצועים\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","report_rf = classification_report(y_test, y_pred_rf)\n","\n","print(f\"Test Accuracy for Random Forest with SMOTE: {accuracy_rf}\")\n","print(f\"Classification Report for Random Forest with SMOTE:\\n{report_rf}\")\n"],"metadata":{"id":"QI6vaSXYoFTx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ניתוח התוצאות לאחר שימוש ב-SMOTE\n","\n","תוצאות האימון לאחר השימוש ב-SMOTE מצביעות על שיפור משמעותי בביצועי המודל:\n","- **דיוק כללי (Accuracy):** 79.41%\n","- **Precision עבור מחלקה 0:** 0.74 (שיעור הדוגמאות שסווגו כ-0 שהן אכן 0)\n","- **Recall עבור מחלקה 0:** 1.00 (שיעור הדוגמאות שהן 0 שסווגו נכון)\n","- **Precision עבור מחלקה 1:** 1.00 (שיעור הדוגמאות שסווגו כ-1 שהן אכן 1)\n","- **Recall עבור מחלקה 1:** 0.50 (שיעור הדוגמאות שהן 1 שסווגו נכון)\n","- **F1-Score עבור מחלקה 0 ו-1:** 0.85 למחלקה 0, 0.67 למחלקה 1\n","\n","### שיפורים נראים:\n","- דיוק ה-Precision וה-Recall למחלקה 1 (AML) השתפרו.\n","- ביצועי המודל הכלליים השתפרו והדיוק על סט הבדיקה עלה ל-79.41%.\n","\n","### הצעדים שנקטנו:\n","1. **איזון הנתונים באמצעות SMOTE:**\n","   - איזון המחלקות על ידי יצירת דוגמאות חדשות למחלקה הפחות נפוצה באמצעות SMOTE.\n","\n","2. **כיול היפר-פרמטרים:**\n","   - שימוש ב-GridSearchCV לכיול היפר-פרמטרים ומציאת השילוב הטוב ביותר למודל Random Forest.\n","\n","### אפשרויות לשיפור נוסף:\n","1. **הנדסת תכונות (Feature Engineering):**\n","   - לנסות ליצור תכונות חדשות או לשלב תכונות קיימות בדרכים חדשות כדי לשפר את היכולת של המודל להבחין בין המחלקות.\n","\n","2. **שימוש במודלים נוספים:**\n","   - לנסות מודלים אחרים כמו XGBoost או LightGBM, שיכולים להתמודד טוב יותר עם נתונים לא מאוזנים.\n","\n","3. **שילוב מודלים (Ensemble Learning):**\n","   - שימוש בשיטות של למידת מכונה משולבת כמו Voting Classifier לשילוב התוצאות של מספר מודלים.\n","\n","4. **כיול המודל (Model Calibration):**\n","   - כיוון המודל כדי לשפר את הדיוק בהערכת ההסתברויות לסיווגים השונים.\n","\n","5. **קרוס-וולידציה משופרת:**\n","   - שימוש בטכניקות קרוס-וולידציה מתקדמות יותר כדי להבטיח שהמודל הכללי בצורה טובה יותר.\n","\n"],"metadata":{"id":"8fimAxdeprXb"}},{"cell_type":"markdown","source":["SVM"],"metadata":{"id":"DG6wEqp5qlhf"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# הגדרת המסווג והיפר-פרמטרים לבדיקת GridSearchCV\n","svc = SVC()\n","param_grid_svc = {\n","    'C': [0.1, 1, 10, 100],      # פרמטר הרגולריזציה\n","    'gamma': [1, 0.1, 0.01, 0.001],  # פרמטר הגרעין\n","    'kernel': ['rbf', 'linear']   # סוג הגרעין\n","}\n","\n","# כיוונון היפר-פרמטרים עם GridSearchCV\n","grid_search_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, cv=5, n_jobs=-1, scoring='accuracy', error_score='raise')\n","grid_search_svc.fit(X_train_encoded, y_train)\n","\n","# קבלת התוצאות הטובות ביותר מה-GridSearchCV\n","best_params_svc = grid_search_svc.best_params_\n","best_model_svc = grid_search_svc.best_estimator_\n","\n","print(f\"Best parameters found for SVM: {best_params_svc}\")\n","\n","# ביצוע Cross-Validation להערכת הביצועים של המודל הטוב ביותר\n","cv_scores_svc = cross_val_score(best_model_svc, X_train_encoded, y_train, cv=5, scoring='accuracy')\n","print(f\"Cross-Validation Scores for SVM: {cv_scores_svc}\")\n","print(f\"Mean CV Accuracy for SVM: {np.mean(cv_scores_svc)}\")\n","\n","# אימון המודל הטוב ביותר על כל נתוני האימון\n","best_model_svc.fit(X_train_encoded, y_train)\n","\n","# ניבוי על נתוני הבדיקה\n","y_pred_svc = best_model_svc.predict(X_test_encoded)\n","\n","# הערכת ביצועים\n","accuracy_svc = accuracy_score(y_test, y_pred_svc)\n","report_svc = classification_report(y_test, y_pred_svc)\n","\n","print(f\"Test Accuracy for SVM: {accuracy_svc}\")\n","print(f\"Classification Report for SVM:\\n{report_svc}\")\n"],"metadata":{"id":"U-ZUkOI4o8xp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PVa_bc4Pqn_A"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1zEUcrFTVJK63ZfoTPUz8S8Qjt6LvqxBe","authorship_tag":"ABX9TyN+tN+HBfc3+FS7mlNBifJ/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}